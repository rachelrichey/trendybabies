{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af50ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb116fbb",
   "metadata": {},
   "source": [
    "First, we want to clean up the hundreds of .txt files in the name subdirectory by combining them all, in order, into one big .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2142ae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote combined CSV with 2149477 rows to: names/all_years.csv\n"
     ]
    }
   ],
   "source": [
    "# naming convention of the name txt files for each year of birth\n",
    "pattern = os.path.join('names', 'yob*.txt')\n",
    "files = sorted(glob(pattern))\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No files found with pattern: {pattern}\")\n",
    "\n",
    "dfs = []\n",
    "for path in files:\n",
    "    # extract yob from file name\n",
    "    fname = os.path.basename(path)\n",
    "    try:\n",
    "        year = int(fname.replace('yob', '').replace('.txt', ''))\n",
    "    except ValueError:\n",
    "        # skip files that don't match the expected pattern\n",
    "        print(f\"Skipping unexpected filename: {fname}\")\n",
    "        continue\n",
    "\n",
    "    # read file\n",
    "    df = pd.read_csv(path, header=None, names=['name', 'sex', 'count'], dtype={'name': str, 'sex': str, 'count': int})\n",
    "    # create year column using yob from file names\n",
    "    df['year'] = year\n",
    "    dfs.append(df)\n",
    "\n",
    "# concatenate dbs, ensure data types are correct + consistent\n",
    "all_names = pd.concat(dfs, ignore_index=True)\n",
    "all_names['count'] = all_names['count'].astype(int)\n",
    "all_names['year'] = all_names['year'].astype(int)\n",
    "\n",
    "# sort by year and popularity\n",
    "all_names = all_names.sort_values(['year', 'count'], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "# write to csv\n",
    "out_path = os.path.join('names', 'all_years.csv')\n",
    "all_names.to_csv(out_path, index=False)\n",
    "print(f\"Wrote combined CSV with {len(all_names)} rows to: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38002308",
   "metadata": {},
   "source": [
    "Now, we need to load the TV shows dataset- allshows.txt. We need to read the file, clean up column names, remove streaming services/non-US shows, and extract the year from the start time for each show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b321a82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>directory</th>\n",
       "      <th>tvrage</th>\n",
       "      <th>TVmaze</th>\n",
       "      <th>start date</th>\n",
       "      <th>end date</th>\n",
       "      <th>number of episodes</th>\n",
       "      <th>run time</th>\n",
       "      <th>network</th>\n",
       "      <th>country</th>\n",
       "      <th>onhiatus</th>\n",
       "      <th>onhiatusdesc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A for Andromeda</td>\n",
       "      <td>AforAndromeda</td>\n",
       "      <td>764.0</td>\n",
       "      <td>6921.0</td>\n",
       "      <td>Oct 1961</td>\n",
       "      <td>Nov 1961</td>\n",
       "      <td>7 eps</td>\n",
       "      <td>45 min</td>\n",
       "      <td>BBC</td>\n",
       "      <td>UK</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ï¿½ La Carte</td>\n",
       "      <td>ALaCarte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61712.0</td>\n",
       "      <td>May 2022</td>\n",
       "      <td>___ ____</td>\n",
       "      <td>6 eps</td>\n",
       "      <td>30 min</td>\n",
       "      <td>Allblk</td>\n",
       "      <td>US</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The A List</td>\n",
       "      <td>AList</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37579.0</td>\n",
       "      <td>Oct 2018</td>\n",
       "      <td>Jun 2021</td>\n",
       "      <td>21 eps</td>\n",
       "      <td>30 min</td>\n",
       "      <td>BBC iPlayer</td>\n",
       "      <td>UK</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A to Z</td>\n",
       "      <td>AtoZ</td>\n",
       "      <td>37968.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Oct 2014</td>\n",
       "      <td>Jan 2015</td>\n",
       "      <td>13 eps</td>\n",
       "      <td>30 min</td>\n",
       "      <td>NBC</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The A Word</td>\n",
       "      <td>AWord</td>\n",
       "      <td>51488.0</td>\n",
       "      <td>11402.0</td>\n",
       "      <td>Mar 2016</td>\n",
       "      <td>Jun 2020</td>\n",
       "      <td>18 eps</td>\n",
       "      <td>60 min</td>\n",
       "      <td>BBC One</td>\n",
       "      <td>UK</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title      directory   tvrage   TVmaze start date  end date  \\\n",
       "0  A for Andromeda  AforAndromeda    764.0   6921.0   Oct 1961  Nov 1961   \n",
       "1     ï¿½ La Carte       ALaCarte      NaN  61712.0   May 2022  ___ ____   \n",
       "2       The A List          AList      NaN  37579.0   Oct 2018  Jun 2021   \n",
       "3           A to Z           AtoZ  37968.0     92.0   Oct 2014  Jan 2015   \n",
       "4       The A Word          AWord  51488.0  11402.0   Mar 2016  Jun 2020   \n",
       "\n",
       "  number of episodes run time      network country  onhiatus onhiatusdesc  \n",
       "0              7 eps   45 min          BBC      UK     False          NaN  \n",
       "1              6 eps   30 min       Allblk      US      True          NaN  \n",
       "2             21 eps   30 min  BBC iPlayer      UK     False          NaN  \n",
       "3             13 eps   30 min          NBC      US     False          NaN  \n",
       "4             18 eps   60 min      BBC One      UK     False          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latin1 encodinng helps us avoid weird characters that sometimes show up\n",
    "shows = pd.read_csv(\"allshows.txt\", encoding=\"latin1\")\n",
    "shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2d6e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>directory</th>\n",
       "      <th>tvrage</th>\n",
       "      <th>tvmaze</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>number_of_episodes</th>\n",
       "      <th>run_time</th>\n",
       "      <th>network</th>\n",
       "      <th>country</th>\n",
       "      <th>onhiatus</th>\n",
       "      <th>onhiatusdesc</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A to Z</td>\n",
       "      <td>AtoZ</td>\n",
       "      <td>37968.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Oct 2014</td>\n",
       "      <td>Jan 2015</td>\n",
       "      <td>13 eps</td>\n",
       "      <td>30 min</td>\n",
       "      <td>NBC</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A to Z</td>\n",
       "      <td>AtoZ</td>\n",
       "      <td>37968.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Oct 2014</td>\n",
       "      <td>Jan 2015</td>\n",
       "      <td>13 eps</td>\n",
       "      <td>30 min</td>\n",
       "      <td>NBC</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aaahh!!! Real Monsters</td>\n",
       "      <td>AaahhRealMonsters</td>\n",
       "      <td>2470.0</td>\n",
       "      <td>8571.0</td>\n",
       "      <td>Oct 1994</td>\n",
       "      <td>Dec 1997</td>\n",
       "      <td>52 eps</td>\n",
       "      <td>30 min</td>\n",
       "      <td>Nick</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994</td>\n",
       "      <td>1997</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aaahh!!! Real Monsters</td>\n",
       "      <td>AaahhRealMonsters</td>\n",
       "      <td>2470.0</td>\n",
       "      <td>8571.0</td>\n",
       "      <td>Oct 1994</td>\n",
       "      <td>Dec 1997</td>\n",
       "      <td>52 eps</td>\n",
       "      <td>30 min</td>\n",
       "      <td>Nick</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994</td>\n",
       "      <td>1997</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aaahh!!! Real Monsters</td>\n",
       "      <td>AaahhRealMonsters</td>\n",
       "      <td>2470.0</td>\n",
       "      <td>8571.0</td>\n",
       "      <td>Oct 1994</td>\n",
       "      <td>Dec 1997</td>\n",
       "      <td>52 eps</td>\n",
       "      <td>30 min</td>\n",
       "      <td>Nick</td>\n",
       "      <td>US</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994</td>\n",
       "      <td>1997</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title          directory   tvrage  tvmaze start_date  \\\n",
       "3                  A to Z               AtoZ  37968.0    92.0   Oct 2014   \n",
       "3                  A to Z               AtoZ  37968.0    92.0   Oct 2014   \n",
       "6  Aaahh!!! Real Monsters  AaahhRealMonsters   2470.0  8571.0   Oct 1994   \n",
       "6  Aaahh!!! Real Monsters  AaahhRealMonsters   2470.0  8571.0   Oct 1994   \n",
       "6  Aaahh!!! Real Monsters  AaahhRealMonsters   2470.0  8571.0   Oct 1994   \n",
       "\n",
       "   end_date number_of_episodes run_time network country  onhiatus  \\\n",
       "3  Jan 2015             13 eps   30 min     NBC      US     False   \n",
       "3  Jan 2015             13 eps   30 min     NBC      US     False   \n",
       "6  Dec 1997             52 eps   30 min    Nick      US     False   \n",
       "6  Dec 1997             52 eps   30 min    Nick      US     False   \n",
       "6  Dec 1997             52 eps   30 min    Nick      US     False   \n",
       "\n",
       "  onhiatusdesc  start_year  end_year  year  \n",
       "3          NaN        2014      2015  2014  \n",
       "3          NaN        2014      2015  2015  \n",
       "6          NaN        1994      1997  1994  \n",
       "6          NaN        1994      1997  1995  \n",
       "6          NaN        1994      1997  1996  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store num of shows before filtering to track efficiency\n",
    "before = len(shows)\n",
    "\n",
    "# clean up column names\n",
    "shows.columns = shows.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# keep only US shows\n",
    "shows = shows[shows['country'] == \"US\"]\n",
    "\n",
    "# remove streaming-exclusive platforms (case-insensitive)\n",
    "streaming_keywords = [\"netflix\", \"hulu\", \"amazon\", \"prime\", \"apple\", \"hbo max\", \"max\", \"paramount\", \"peacock\", \"roku\", \"allblk\"]\n",
    "shows = shows[~shows['network'].str.lower().str.contains(\"|\".join(streaming_keywords), na=False)]\n",
    "\n",
    "# remove non-scripted shows (case-insensitive)\n",
    "non_scripted_keywords = [\n",
    "    \"late night\", \"latenight\", \"late-night\",\n",
    "    \"late late show\", \"lateshow\",\n",
    "    \"tonight show\", \"latenight\",\n",
    "    \"good morning\", \"morning show\", \"daytime\", \"today show\",\n",
    "    \"news\", \"documentary\",\n",
    "    \"special\", \"report\",\n",
    "    \"variety\", \"circus\", \"talent\", \"competition\",\n",
    "    \"game show\", \"gameshow\", \"interview\", \"panel\",\n",
    "    \"colbert\", \"fallon\", \"kimmel\", \"myers\",\n",
    "    \"ellen\", \"oprah\", \"maury\", \"steve harvey\",\n",
    "    \"trevor noah\", \"conan\", \"letterman\", \"leno\", \"carson\",\n",
    "    \"corden\", \"movie\", \"daily\"\n",
    "]\n",
    "shows = shows[~shows['title'].str.lower().str.contains(\"|\".join(non_scripted_keywords), na=False)]\n",
    "\n",
    "# remove anything that ends with \" show\" (case-insensitive)\n",
    "shows = shows[~shows['title'].str.lower().str.endswith(\" show\")]\n",
    "\n",
    "# remove invalid start dates\n",
    "shows = shows[shows['start_date'].notna()]\n",
    "shows = shows[~shows['start_date'].str.contains(\"___\", na=False)]\n",
    "\n",
    "def extract_year(date):\n",
    "    # extract the last 4-digit number in a string so we can isolate just the year\n",
    "    match = re.search(r\"\\b(19\\d{2}|20\\d{2})\\b\", str(date))\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "# extract start and end years\n",
    "shows['start_year'] = shows['start_date'].apply(extract_year)\n",
    "shows['end_year']   = shows['end_date'].apply(extract_year)\n",
    "\n",
    "# remove rows where either start or end year is missing\n",
    "shows = shows.dropna(subset=['start_year', 'end_year'])\n",
    "\n",
    "# convert years to ints\n",
    "shows['start_year'] = shows['start_year'].astype(int)\n",
    "shows['end_year'] = shows['end_year'].astype(int)\n",
    "\n",
    "# expand shows across all years aired\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in shows.iterrows():\n",
    "    for y in range(row['start_year'], row['end_year'] + 1):\n",
    "        new_row = row.copy()\n",
    "        new_row['year'] = y\n",
    "        expanded_rows.append(new_row)\n",
    "\n",
    "expanded_shows = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# check if it worked\n",
    "expanded_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3b626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after filtering:  6899\n",
      "Rows removed:  6156\n"
     ]
    }
   ],
   "source": [
    "after = len(shows)\n",
    "print(\"Rows after filtering: \", after)\n",
    "print(\"Rows removed: \", before - after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a45e1",
   "metadata": {},
   "source": [
    "For now, the best way we have found to measure popularity is based on how many episodes that show has. Intuitively, this makes sense- if a show is running for many years, they keep getting renewed for new seasons, meaning it is well-liked. An unpopular show will likely have less episodes. For each year, we say that the most popular show is the show with the most episodes that is still streaming during that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63c6ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>episodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>Lights Out (1946)</td>\n",
       "      <td>1946</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>Lights Out (1946)</td>\n",
       "      <td>1947</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>Studio One</td>\n",
       "      <td>1948</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>Studio One</td>\n",
       "      <td>1949</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>Studio One</td>\n",
       "      <td>1950</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title  year  episodes\n",
       "6587   Lights Out (1946)  1946     160.0\n",
       "6587   Lights Out (1946)  1947     160.0\n",
       "10955         Studio One  1948     465.0\n",
       "10955         Studio One  1949     465.0\n",
       "10955         Studio One  1950     465.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the number of episodes for our popularity metric\n",
    "def extract_eps(x):\n",
    "    match = re.search(r\"(\\d+)\", str(x))\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "expanded_shows['episodes'] = expanded_shows['number_of_episodes'].apply(extract_eps)\n",
    "expanded_shows['episodes'] = expanded_shows['episodes'].fillna(0)\n",
    "\n",
    "# find the most popular show each year\n",
    "top_show_per_year = expanded_shows.sort_values(['year', 'episodes'], ascending=[True, False]).groupby('year').head(1)\n",
    "top_show_per_year[['title', 'year', 'episodes']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8d59477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year                              title  episodes\n",
      "6725   1949             The Lone Ranger (1949)     221.0\n",
      "6725   1950             The Lone Ranger (1949)     221.0\n",
      "3220   1951                     Dragnet (1951)     276.0\n",
      "2865   1952                  Death Valley Days     452.0\n",
      "2865   1953                  Death Valley Days     452.0\n",
      "6312   1954                      Lassie (1954)     591.0\n",
      "4753   1955                           Gunsmoke     635.0\n",
      "4753   1956                           Gunsmoke     635.0\n",
      "4753   1957                           Gunsmoke     635.0\n",
      "4753   1958                           Gunsmoke     635.0\n",
      "4753   1959                           Gunsmoke     635.0\n",
      "4753   1960                           Gunsmoke     635.0\n",
      "4753   1961                           Gunsmoke     635.0\n",
      "4753   1962                           Gunsmoke     635.0\n",
      "4753   1963                           Gunsmoke     635.0\n",
      "4753   1964                           Gunsmoke     635.0\n",
      "4753   1965                           Gunsmoke     635.0\n",
      "2747   1966                Dark Shadows (1966)    1225.0\n",
      "2747   1967                Dark Shadows (1966)    1225.0\n",
      "2747   1968                Dark Shadows (1966)    1225.0\n",
      "2747   1969                Dark Shadows (1966)    1225.0\n",
      "2747   1970                Dark Shadows (1966)    1225.0\n",
      "2747   1971                Dark Shadows (1966)    1225.0\n",
      "4753   1972                           Gunsmoke     635.0\n",
      "4753   1973                           Gunsmoke     635.0\n",
      "4753   1974                           Gunsmoke     635.0\n",
      "4753   1975                           Gunsmoke     635.0\n",
      "7163   1976         Mary Hartman, Mary Hartman     307.0\n",
      "7163   1977         Mary Hartman, Mary Hartman     307.0\n",
      "2671   1978                      Dallas (1978)     357.0\n",
      "2671   1979                      Dallas (1978)     357.0\n",
      "2671   1980                      Dallas (1978)     357.0\n",
      "2671   1981                      Dallas (1978)     357.0\n",
      "2671   1982                      Dallas (1978)     357.0\n",
      "2671   1983                      Dallas (1978)     357.0\n",
      "2671   1984                      Dallas (1978)     357.0\n",
      "2671   1985                      Dallas (1978)     357.0\n",
      "2671   1986                      Dallas (1978)     357.0\n",
      "2671   1987                      Dallas (1978)     357.0\n",
      "2671   1988                      Dallas (1978)     357.0\n",
      "2671   1989                      Dallas (1978)     357.0\n",
      "2671   1990                      Dallas (1978)     357.0\n",
      "2671   1991                      Dallas (1978)     357.0\n",
      "6202   1992                      Knots Landing     344.0\n",
      "6202   1993                      Knots Landing     344.0\n",
      "3496   1994                          ER (1994)     331.0\n",
      "3496   1995                          ER (1994)     331.0\n",
      "3496   1996                          ER (1994)     331.0\n",
      "3496   1997                          ER (1994)     331.0\n",
      "3496   1998                          ER (1994)     331.0\n",
      "3496   1999                          ER (1994)     331.0\n",
      "2581   2000  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2001  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2002  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2003  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2004  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2005  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2006  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2007  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2008  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2009  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2010  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2011  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2012  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2013  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2014  C.S.I.: Crime Scene Investigation     336.0\n",
      "2581   2015  C.S.I.: Crime Scene Investigation     336.0\n",
      "11053  2016                Supernatural (2005)     327.0\n",
      "11053  2017                Supernatural (2005)     327.0\n",
      "11053  2018                Supernatural (2005)     327.0\n",
      "11053  2019                Supernatural (2005)     327.0\n",
      "11053  2020                Supernatural (2005)     327.0\n",
      "7984   2021                  NCIS: Los Angeles     323.0\n",
      "7984   2022                  NCIS: Los Angeles     323.0\n",
      "7984   2023                  NCIS: Los Angeles     323.0\n",
      "1336   2024                        Blue Bloods     293.0\n",
      "11117  2025                    S.W.A.T. (2017)     163.0\n"
     ]
    }
   ],
   "source": [
    "# manually account for outlier shows that weren't caught by previous filtering, yet still show up as most popular\n",
    "outliers = [\"Bozo's Circus (Chicago)\", \"Lights Out (1946)\", \"Walt Disney Presents\", \"Family Classics\", \n",
    "            \"ABC's Wide World of Entertainment\", \"WGN Presents\", \"Politically Incorrect\", \"Soundstage\",\n",
    "            \"Chelsea Lately\", \"AM Chicago\", \"Soul Train\", \"Cops\", \"PM Magazine (Chicago)\", \"Mister Rogers' Neighborhood\",\n",
    "            \"After Midnight\", \"Friday Night Videos\", \"Later with Bob Costas\", \"Hee Haw\", \"The Wonderful World of Disney (1961)\",\n",
    "            \"Mystery!\", \"Power Rangers\", \"Craig of the Creek\", \"Unsolved Mysteries (1987)\", \"The Real World\", \"Modern Marvels\", \n",
    "            \"The Late Show Starring Joan Rivers\", \"Creature Features\", \"Garfield and Friends\", \"The Smurfs\", \"Beyblade\", \"How It's Made\",\n",
    "            \"Animaniacs (1993)\", \"Forensic Files\", \"Mike & Maty\", \"The E! True Hollywood Story\", \"Are You Smarter Than a 5th Grader? (2007)\",\n",
    "            \"@Midnight\", \"WGN Sunday Matinee\", \"Later with Greg Kinnear\", \"True Life\", \"World Poker Tour\", \"Trading Spaces\", \"What Not to Wear (US)\",\n",
    "            \"Cash Cab\", \"Anderson\", \"The Bonnie Hunt Show (2008)\", \"MadTV\", \"Studio One\", \"The Philco Television Playhouse\",\n",
    "            \"Lux Video Theatre\", \"Suspense (1949)\", \"Robert Montgomery Presents\", \"The Jack Benny Program\", \"Actors Studio\",\n",
    "            \"The Ford Television Theatre\"\n",
    "            ]\n",
    "expanded_shows = expanded_shows[~expanded_shows['title'].isin(outliers)]\n",
    "\n",
    "top_show_per_year = expanded_shows.sort_values(\n",
    "    ['year', 'episodes'], ascending=[True, False]\n",
    ").groupby('year').head(1)\n",
    "\n",
    "print(top_show_per_year[['year', 'title', 'episodes']].sort_values('year').to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fad77d",
   "metadata": {},
   "source": [
    "We need to create an empty table to track the \"influence\" each show has had on baby names during that year. We will fill in the top 5 character names per show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e57a2a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>character_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>The Lone Ranger (1949)</td>\n",
       "      <td>1949</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>The Lone Ranger (1949)</td>\n",
       "      <td>1950</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>Dragnet (1951)</td>\n",
       "      <td>1951</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>Death Valley Days</td>\n",
       "      <td>1952</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>Death Valley Days</td>\n",
       "      <td>1953</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  year character_names\n",
       "6725  The Lone Ranger (1949)  1949                \n",
       "6725  The Lone Ranger (1949)  1950                \n",
       "3220          Dragnet (1951)  1951                \n",
       "2865       Death Valley Days  1952                \n",
       "2865       Death Valley Days  1953                "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influence = top_show_per_year[['title', 'year']].copy()\n",
    "influence['character_names'] = \"\" \n",
    "influence.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d25a32",
   "metadata": {},
   "source": [
    "Now, we need to prepare the baby name data by using within-year ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ef1c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>M</td>\n",
       "      <td>9655</td>\n",
       "      <td>1880</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William</td>\n",
       "      <td>M</td>\n",
       "      <td>9532</td>\n",
       "      <td>1880</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary</td>\n",
       "      <td>F</td>\n",
       "      <td>7065</td>\n",
       "      <td>1880</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James</td>\n",
       "      <td>M</td>\n",
       "      <td>5927</td>\n",
       "      <td>1880</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charles</td>\n",
       "      <td>M</td>\n",
       "      <td>5348</td>\n",
       "      <td>1880</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name sex  count  year  rank\n",
       "0     John   M   9655  1880   1.0\n",
       "1  William   M   9532  1880   2.0\n",
       "2     Mary   F   7065  1880   3.0\n",
       "3    James   M   5927  1880   4.0\n",
       "4  Charles   M   5348  1880   5.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names['rank'] = all_names.groupby('year')['count'].rank(ascending=False, method='dense')\n",
    "all_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bbfafa",
   "metadata": {},
   "source": [
    "Finally, we will merge each name/year row with the show of that year to join these two datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
